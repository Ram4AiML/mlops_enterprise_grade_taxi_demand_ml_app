{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_PROJECT_NAME = 'taxi_demand_hwfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.paths import PARENT_DIR\n",
    "\n",
    "# load key-value pairs from .env file located in the parent directory\n",
    "load_dotenv(PARENT_DIR / '.env')\n",
    "\n",
    "HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/241814\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(\n",
    "    project=HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=HOPSWORKS_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURE_GROUP_NAME = 'time_series_hourly_feature_group'\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': [{'approximateNumDistinctValues': 15903,\n",
       "   'isDataTypeInferred': 'false',\n",
       "   'dataType': 'String',\n",
       "   'column': 'pickup_hour',\n",
       "   'numRecordsNull': 0,\n",
       "   'completeness': 1,\n",
       "   'numRecordsNonNull': 4235760},\n",
       "  {'dataType': 'Integral',\n",
       "   'column': 'rides',\n",
       "   'numRecordsNull': 0,\n",
       "   'sum': 70736824,\n",
       "   'completeness': 1,\n",
       "   'approximateNumDistinctValues': 649,\n",
       "   'isDataTypeInferred': 'false',\n",
       "   'mean': 16.699913120667837,\n",
       "   'maximum': 1115,\n",
       "   'stdDev': 50.46135035982242,\n",
       "   'minimum': 0,\n",
       "   'numRecordsNonNull': 4235760,\n",
       "   'approxPercentiles': []},\n",
       "  {'dataType': 'Integral',\n",
       "   'column': 'pickup_location_id',\n",
       "   'numRecordsNull': 0,\n",
       "   'sum': 563356080.0,\n",
       "   'completeness': 1,\n",
       "   'approximateNumDistinctValues': 267,\n",
       "   'isDataTypeInferred': 'false',\n",
       "   'mean': 133,\n",
       "   'maximum': 265,\n",
       "   'stdDev': 76.49836599562113,\n",
       "   'minimum': 1,\n",
       "   'numRecordsNonNull': 4235760,\n",
       "   'approxPercentiles': []},\n",
       "  {'dataType': 'Integral',\n",
       "   'column': 'pickup_ts',\n",
       "   'numRecordsNull': 0,\n",
       "   'sum': 7.073295875856e+18,\n",
       "   'completeness': 1,\n",
       "   'approximateNumDistinctValues': 16037,\n",
       "   'isDataTypeInferred': 'false',\n",
       "   'mean': 1669900059459.4595,\n",
       "   'maximum': 1701756000000.0,\n",
       "   'stdDev': 16846731890.455187,\n",
       "   'minimum': 1640995200000.0,\n",
       "   'numRecordsNonNull': 4235760,\n",
       "   'approxPercentiles': []}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom code - To get the count of features from a fs group using get_statistics\n",
    "\n",
    "fs = feature_group.get_statistics(commit_time=None)\n",
    "\n",
    "fs.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with null values for 'pickup_hour': 0\n",
      "Number of records with non-null values for 'pickup_hour': 4235760\n",
      "Sum of null and non-null records: 4235760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find statistics for 'pickup_hour' column from the above fs.content\n",
    "pickup_hour_stats = next((col for col in fs.content['columns'] if col['column'] == 'pickup_hour'), None)\n",
    "\n",
    "# Print counts and sum if statistics found\n",
    "if pickup_hour_stats:\n",
    "    num_records_null = pickup_hour_stats['numRecordsNull']\n",
    "    num_records_non_null = pickup_hour_stats['numRecordsNonNull']\n",
    "\n",
    "    print(f\"Number of records with null values for 'pickup_hour': {num_records_null}\")\n",
    "    print(f\"Number of records with non-null values for 'pickup_hour': {num_records_non_null}\")\n",
    "    print(f\"Sum of null and non-null records: {num_records_null + num_records_non_null}\")\n",
    "else:\n",
    "    print(\"Statistics for 'pickup_hour' column not found in the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Cautious : Use delete() only if you really need it ***\n",
    "# Delete Feature View\n",
    "feature_view = feature_store.get_feature_view(\"time_series_hourly_feature_view\",version=1)\n",
    "#feature_view.delete()\n",
    "\n",
    "# Order of feature group and feature view deletion: 1st feature view accosiated with the fg and then fg.\n",
    "# Here Parent is fg and child is fv, first delete child then parent if needed; but \n",
    "# not vice versa to avoid compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not establish connection to ArrowFlight Server. (Flight returned timeout error, with message: Deadline Exceeded) Will fall back to hive/spark for this session. If the error persists, you can disable using ArrowFlight by changing the cluster configuration (set 'enable_flyingduck'='false').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Reading data from Hopsworks, using Hive           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_view\u001b[39m.\u001b[39;49mtraining_data(\n\u001b[1;32m      2\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTime-series hourly taxi rides\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/feature_view.py:1658\u001b[0m, in \u001b[0;36mFeatureView.training_data\u001b[0;34m(self, start_time, end_time, description, extra_filter, statistics_config, read_options, spine)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39mCreate the metadata for a training dataset and get the corresponding training data from the offline feature store.\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39mThis returns the training data in memory and does not materialise data in storage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[39m    (X, y): Tuple of dataframe of features and labels. If there are no labels, y returns `None`.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m td \u001b[39m=\u001b[39m training_dataset\u001b[39m.\u001b[39mTrainingDataset(\n\u001b[1;32m   1644\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m   1645\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     extra_filter\u001b[39m=\u001b[39mextra_filter,\n\u001b[1;32m   1657\u001b[0m )\n\u001b[0;32m-> 1658\u001b[0m td, df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_engine\u001b[39m.\u001b[39;49mget_training_data(\n\u001b[1;32m   1659\u001b[0m     \u001b[39mself\u001b[39;49m, read_options, training_dataset_obj\u001b[39m=\u001b[39;49mtd, spine\u001b[39m=\u001b[39;49mspine\n\u001b[1;32m   1660\u001b[0m )\n\u001b[1;32m   1661\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1662\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mIncremented version to `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(td\u001b[39m.\u001b[39mversion),\n\u001b[1;32m   1663\u001b[0m     util\u001b[39m.\u001b[39mVersionWarning,\n\u001b[1;32m   1664\u001b[0m )\n\u001b[1;32m   1665\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:279\u001b[0m, in \u001b[0;36mFeatureViewEngine.get_training_data\u001b[0;34m(self, feature_view_obj, read_options, splits, training_dataset_obj, training_dataset_version, spine)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_group_accessibility(feature_view_obj)\n\u001b[1;32m    271\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch_query(\n\u001b[1;32m    272\u001b[0m         feature_view_obj,\n\u001b[1;32m    273\u001b[0m         training_dataset_version\u001b[39m=\u001b[39mtd_updated\u001b[39m.\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         spine\u001b[39m=\u001b[39mspine,\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 279\u001b[0m     split_df \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mget_instance()\u001b[39m.\u001b[39;49mget_training_data(\n\u001b[1;32m    280\u001b[0m         td_updated, feature_view_obj, query, read_options\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_training_dataset_statistics(\n\u001b[1;32m    283\u001b[0m         feature_view_obj, td_updated, split_df, calc_stat\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[39m# split df into features and labels df\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/engine/python.py:550\u001b[0m, in \u001b[0;36mEngine.get_training_data\u001b[0;34m(self, training_dataset_obj, feature_view_obj, query_obj, read_options)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_transform_split_df(\n\u001b[1;32m    547\u001b[0m         query_obj, training_dataset_obj, feature_view_obj, read_options\n\u001b[1;32m    548\u001b[0m     )\n\u001b[1;32m    549\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     df \u001b[39m=\u001b[39m query_obj\u001b[39m.\u001b[39;49mread(read_options\u001b[39m=\u001b[39;49mread_options)\n\u001b[1;32m    551\u001b[0m     transformation_function_engine\u001b[39m.\u001b[39mTransformationFunctionEngine\u001b[39m.\u001b[39mpopulate_builtin_transformation_functions(\n\u001b[1;32m    552\u001b[0m         training_dataset_obj, feature_view_obj, df\n\u001b[1;32m    553\u001b[0m     )\n\u001b[1;32m    554\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_transformation_function(\n\u001b[1;32m    555\u001b[0m         training_dataset_obj\u001b[39m.\u001b[39mtransformation_functions, df\n\u001b[1;32m    556\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/constructor/query.py:153\u001b[0m, in \u001b[0;36mQuery.read\u001b[0;34m(self, online, dataframe_type, read_options)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoins) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39min\u001b[39;00m [f\u001b[39m.\u001b[39mtype \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m schema]:\n\u001b[1;32m    149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    150\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPandas types casting only supported for feature_group.read()/query.select_all()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m engine\u001b[39m.\u001b[39;49mget_instance()\u001b[39m.\u001b[39;49msql(\n\u001b[1;32m    154\u001b[0m     sql_query,\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_store_name,\n\u001b[1;32m    156\u001b[0m     online_conn,\n\u001b[1;32m    157\u001b[0m     dataframe_type,\n\u001b[1;32m    158\u001b[0m     read_options,\n\u001b[1;32m    159\u001b[0m     schema,\n\u001b[1;32m    160\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/engine/python.py:106\u001b[0m, in \u001b[0;36mEngine.sql\u001b[0;34m(self, sql_query, feature_store, online_conn, dataframe_type, read_options, schema)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msql\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     sql_query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m online_conn:\n\u001b[0;32m--> 106\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sql_offline(\n\u001b[1;32m    107\u001b[0m             sql_query,\n\u001b[1;32m    108\u001b[0m             feature_store,\n\u001b[1;32m    109\u001b[0m             dataframe_type,\n\u001b[1;32m    110\u001b[0m             schema,\n\u001b[1;32m    111\u001b[0m             hive_config\u001b[39m=\u001b[39;49mread_options\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mhive_config\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mif\u001b[39;49;00m read_options \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdbc(\n\u001b[1;32m    115\u001b[0m             sql_query, online_conn, dataframe_type, read_options, schema\n\u001b[1;32m    116\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/engine/python.py:144\u001b[0m, in \u001b[0;36mEngine._sql_offline\u001b[0;34m(self, sql_query, feature_store, dataframe_type, schema, hive_config)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    143\u001b[0m             warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 144\u001b[0m             result_df \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39;49mrun_with_loading_animation(\n\u001b[1;32m    145\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mReading data from Hopsworks, using Hive\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    146\u001b[0m                 pd\u001b[39m.\u001b[39;49mread_sql,\n\u001b[1;32m    147\u001b[0m                 sql_query,\n\u001b[1;32m    148\u001b[0m                 hive_conn,\n\u001b[1;32m    149\u001b[0m             )\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m schema:\n\u001b[1;32m    152\u001b[0m     result_df \u001b[39m=\u001b[39m Engine\u001b[39m.\u001b[39mcast_columns(result_df, schema)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/util.py:345\u001b[0m, in \u001b[0;36mrun_with_loading_animation\u001b[0;34m(message, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    346\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    347\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:564\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    561\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    565\u001b[0m         sql,\n\u001b[1;32m    566\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    567\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    568\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    569\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    570\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    571\u001b[0m     )\n\u001b[1;32m    573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:2092\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_iterator(\n\u001b[1;32m   2083\u001b[0m         cursor,\n\u001b[1;32m   2084\u001b[0m         chunksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2089\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   2090\u001b[0m     )\n\u001b[1;32m   2091\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2092\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetchall_as_list(cursor)\n\u001b[1;32m   2093\u001b[0m     cursor\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   2095\u001b[0m     frame \u001b[39m=\u001b[39m _wrap_result(\n\u001b[1;32m   2096\u001b[0m         data,\n\u001b[1;32m   2097\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   2102\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:2106\u001b[0m, in \u001b[0;36mSQLiteDatabase._fetchall_as_list\u001b[0;34m(self, cur)\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetchall_as_list\u001b[39m(\u001b[39mself\u001b[39m, cur):\n\u001b[0;32m-> 2106\u001b[0m     result \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39;49mfetchall()\n\u001b[1;32m   2107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   2108\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(result)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pyhive/common.py:136\u001b[0m, in \u001b[0;36mDBAPICursor.fetchall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetchall\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fetch all (remaining) rows of a query result, returning them as a sequence of sequences\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    (e.g. a list of tuples).\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[39m    An :py:class:`~pyhive.exc.Error` (or subclass) exception is raised if the previous call to\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    :py:meth:`execute` did not produce any result set or no call was issued yet.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetchone, \u001b[39mNone\u001b[39;49;00m))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pyhive/common.py:105\u001b[0m, in \u001b[0;36mDBAPICursor.fetchone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mProgrammingError(\u001b[39m\"\u001b[39m\u001b[39mNo query yet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[39m# Sleep until we're done or we have some data to return\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_while(\u001b[39mlambda\u001b[39;49;00m: \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data \u001b[39mand\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state \u001b[39m!=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_STATE_FINISHED)\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data:\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pyhive/common.py:45\u001b[0m, in \u001b[0;36mDBAPICursor._fetch_while\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_while\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m     44\u001b[0m     \u001b[39mwhile\u001b[39;00m fn():\n\u001b[0;32m---> 45\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_more()\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m fn():\n\u001b[1;32m     47\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll_interval)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/pyhive/hive.py:429\u001b[0m, in \u001b[0;36mCursor._fetch_more\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mraise\u001b[39;00m ProgrammingError(\u001b[39m\"\u001b[39m\u001b[39mNo result set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m req \u001b[39m=\u001b[39m ttypes\u001b[39m.\u001b[39mTFetchResultsReq(\n\u001b[1;32m    425\u001b[0m     operationHandle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle,\n\u001b[1;32m    426\u001b[0m     orientation\u001b[39m=\u001b[39mttypes\u001b[39m.\u001b[39mTFetchOrientation\u001b[39m.\u001b[39mFETCH_NEXT,\n\u001b[1;32m    427\u001b[0m     maxRows\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39marraysize,\n\u001b[1;32m    428\u001b[0m )\n\u001b[0;32m--> 429\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mFetchResults(req)\n\u001b[1;32m    430\u001b[0m _check_status(response)\n\u001b[1;32m    431\u001b[0m schema \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/TCLIService/TCLIService.py:717\u001b[0m, in \u001b[0;36mClient.FetchResults\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m - req\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_FetchResults(req)\n\u001b[0;32m--> 717\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecv_FetchResults()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/TCLIService/TCLIService.py:729\u001b[0m, in \u001b[0;36mClient.recv_FetchResults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecv_FetchResults\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    728\u001b[0m     iprot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iprot\n\u001b[0;32m--> 729\u001b[0m     (fname, mtype, rseqid) \u001b[39m=\u001b[39m iprot\u001b[39m.\u001b[39;49mreadMessageBegin()\n\u001b[1;32m    730\u001b[0m     \u001b[39mif\u001b[39;00m mtype \u001b[39m==\u001b[39m TMessageType\u001b[39m.\u001b[39mEXCEPTION:\n\u001b[1;32m    731\u001b[0m         x \u001b[39m=\u001b[39m TApplicationException()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/thrift/protocol/TBinaryProtocol.py:134\u001b[0m, in \u001b[0;36mTBinaryProtocol.readMessageBegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadMessageBegin\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m     sz \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadI32()\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m sz \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m         version \u001b[39m=\u001b[39m sz \u001b[39m&\u001b[39m TBinaryProtocol\u001b[39m.\u001b[39mVERSION_MASK\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/thrift/protocol/TBinaryProtocol.py:217\u001b[0m, in \u001b[0;36mTBinaryProtocol.readI32\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadI32\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m     buff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrans\u001b[39m.\u001b[39;49mreadAll(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     val, \u001b[39m=\u001b[39m unpack(\u001b[39m'\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m'\u001b[39m, buff)\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/thrift/transport/TTransport.py:62\u001b[0m, in \u001b[0;36mTTransportBase.readAll\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m     60\u001b[0m have \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[39mwhile\u001b[39;00m (have \u001b[39m<\u001b[39m sz):\n\u001b[0;32m---> 62\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(sz \u001b[39m-\u001b[39;49m have)\n\u001b[1;32m     63\u001b[0m     chunkLen \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m     64\u001b[0m     have \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunkLen\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/thrift/transport/TTransport.py:164\u001b[0m, in \u001b[0;36mTBufferedTransport.read\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ret) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n\u001b[0;32m--> 164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__rbuf \u001b[39m=\u001b[39m BufferIO(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__trans\u001b[39m.\u001b[39;49mread(\u001b[39mmax\u001b[39;49m(sz, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__rbuf_size)))\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__rbuf\u001b[39m.\u001b[39mread(sz)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/thrift/transport/TSocket.py:150\u001b[0m, in \u001b[0;36mTSocket.read\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, sz):\n\u001b[1;32m    149\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         buff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle\u001b[39m.\u001b[39;49mrecv(sz)\n\u001b[1;32m    151\u001b[0m     \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m         \u001b[39mif\u001b[39;00m (e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mECONNRESET \u001b[39mand\u001b[39;00m\n\u001b[1;32m    153\u001b[0m                 (sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mfreebsd\u001b[39m\u001b[39m'\u001b[39m))):\n\u001b[1;32m    154\u001b[0m             \u001b[39m# freebsd and Mach don't follow POSIX semantic of recv\u001b[39;00m\n\u001b[1;32m    155\u001b[0m             \u001b[39m# and fail with ECONNRESET if peer performed shutdown.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m             \u001b[39m# See corresponding comment and code in TSocket::read()\u001b[39;00m\n\u001b[1;32m    157\u001b[0m             \u001b[39m# in lib/cpp/src/transport/TSocket.cpp.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1102\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_view.training_data(\n",
    "    description='Time-series hourly taxi rides',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the feature group name and version to delete\n",
    "FEATURE_GROUP_NAME = 'time_series_hourly_feature_group'\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "# Get the feature group object with the name and version\n",
    "feature_group = feature_store.get_feature_group(FEATURE_GROUP_NAME,FEATURE_GROUP_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobWarning: All jobs associated to feature group `time_series_hourly_feature_group`, version `1` will be removed.\n"
     ]
    }
   ],
   "source": [
    "# *** Cautious : Use delete() only if you really need it ***\n",
    "# Delete the feature group \n",
    "feature_group.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JobWarning: All jobs associated to feature group `time_series_hourly_feature_group`, version `2` will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_api.py:101\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m feature_view\u001b[39m.\u001b[39mFeatureView\u001b[39m.\u001b[39mfrom_response_json(\n\u001b[0;32m--> 101\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_send_request(\n\u001b[1;32m    102\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_GET, path, {\u001b[39m\"\u001b[39;49m\u001b[39mexpand\u001b[39;49m\u001b[39m\"\u001b[39;49m: [\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m]}\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/client/base.py:179\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/241814/featurestores/241733/featureview/time_series_hourly_feature_view/version/2). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270009,\"usrMsg\":\"Cannot construct the query. Parent feature groups of the following features are not available anymore: pickup_hour, rides, pickup_location_id\",\"errorMsg\":\"Featuregroup wasn\\'t found.\"}', error code: 270009, error msg: Featuregroup wasn't found., user msg: Cannot construct the query. Parent feature groups of the following features are not available anymore: pickup_hour, rides, pickup_location_id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_view \u001b[39m=\u001b[39m feature_store\u001b[39m.\u001b[39;49mget_feature_view(\u001b[39m\"\u001b[39;49m\u001b[39mtime_series_hourly_feature_view\u001b[39;49m\u001b[39m\"\u001b[39;49m,version\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m feature_view\u001b[39m.\u001b[39mdelete()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/feature_store.py:1555\u001b[0m, in \u001b[0;36mFeatureStore.get_feature_view\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1549\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo version provided for getting feature view `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`, defaulting to `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1550\u001b[0m             name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_VERSION\n\u001b[1;32m   1551\u001b[0m         ),\n\u001b[1;32m   1552\u001b[0m         util\u001b[39m.\u001b[39mVersionWarning,\n\u001b[1;32m   1553\u001b[0m     )\n\u001b[1;32m   1554\u001b[0m     version \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m-> 1555\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_engine\u001b[39m.\u001b[39;49mget(name, version)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:96\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, name, version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m version:\n\u001b[0;32m---> 96\u001b[0m         fv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_api\u001b[39m.\u001b[39;49mget_by_name_version(name, version)\n\u001b[1;32m     97\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattach_transformation_function(fv)\n\u001b[1;32m     98\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-drFRWbj0-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_api.py:107\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mjson()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrorCode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m270009\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot get back the feature view because the query defined is no longer valid.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m or `FeatureView.clean`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-drFRWbj0-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
